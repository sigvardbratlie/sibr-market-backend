options:
  logging: CLOUD_LOGGING_ONLY


steps:
# STEP 0: Check the commit message.
- name: 'gcr.io/cloud-builders/git' # <-- THIS IS THE FIX. Use the official git image.
  id: 'Check-commit-message'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    commit_message=$(git log -1 --pretty=%B "${COMMIT_SHA}")
    if [[ ! "$commit_message" =~ "gcloud build" ]]; then
      echo "Keyword 'gcloud build' is missing. Failing build."
      exit 1
    else
      echo "Keyword found. Proceeding with build."
    fi

## ---- STEG 1: Build the Docker images in parallel ----
#- name: 'gcr.io/cloud-builders/docker'
#  id: 'build-scraping'
#  args:
#    - 'build'
#    - '-t'
#    - 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/scraping:${COMMIT_SHA}'
#    - './scraping'

#- name: 'gcr.io/cloud-builders/docker'
#  id: 'build-geocoding'
#  args:
#    - 'build'
#    - '-t'
#    - 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/geocoding:${COMMIT_SHA}'
#    - './geocoding'

#- name: 'gcr.io/cloud-builders/docker'
#  id: 'build-modeling'
#  args:
#    - 'build'
#    - '-t'
#    - 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/modeling:${COMMIT_SHA}'
#    - './modeling'

## ---- STEP 2: Push to Artifact Registry ----
#- name: 'gcr.io/cloud-builders/docker'
#  id: 'push-scraping'
#  waitFor: ['build-scraping']
#  args: ['push', 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/scraping:${COMMIT_SHA}']

#- name: 'gcr.io/cloud-builders/docker'
#  id: 'push-geocoding'
#  waitFor: ['build-geocoding']
#  args: ['push', 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/geocoding:${COMMIT_SHA}']

#- name: 'gcr.io/cloud-builders/docker'
#  id: 'push-modeling'
#  waitFor: ['build-modeling']
#  args: ['push', 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/modeling:${COMMIT_SHA}']

## ---- STEG 3: Compile the pipeline ----
#- name: 'python:3.11'
#  id: 'compile-pipeline'
#  waitFor: ['push-scraping', 'push-geocoding', 'push-modeling']
#  entrypoint: 'bash'
#  args:
#  - '-c'
#  - |
#    sed -i "s|SCRAPING_IMAGE_PLACEHOLDER|europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/scraping:${COMMIT_SHA}|g" pipelines/pipeline.py
#    sed -i "s|GEOCODING_IMAGE_PLACEHOLDER|europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/geocoding:${COMMIT_SHA}|g" pipelines/pipeline.py
#    sed -i "s|MODELING_IMAGE_PLACEHOLDER|europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/modeling:${COMMIT_SHA}|g" pipelines/pipeline.py

#    # Nå, installer dependencies og kompiler filen som nå har de korrekte URI-ene
#    pip install -r pipelines/requirements.txt && \
#    python pipelines/pipeline.py

# ---- STEP 4: Oppdater eller opprett pipeline-schedule ----
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: 'submit-or-update-pipeline'
  #waitFor: ['compile-pipeline']
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      set -e # Avslutt scriptet umiddelbart hvis en kommando feiler

      # Installer Python dependencies
      apt-get update && apt-get install -y python3-venv

      # Opprett og aktiver virtuelt miljø
      python3 -m venv venv
      source venv/bin/activate
      
      # Installer pakker
      pip install -r pipelines/requirements.txt

      # Lag Python-skriptet for å oppdatere eller opprette
      cat <<EOF > submit_or_update_schedule.py
      import google.cloud.aiplatform as aiplatform
      import os

      PROJECT_ID = os.getenv('PROJECT_ID', 'sibr-market')
      LOCATION = os.getenv('LOCATION', 'europe-west1')
      SCHEDULE_NAME = 'sibr-market-schedule'
      PIPELINE_SPEC_URI = 'gs://sibr-market/sibr_market_pipeline.json'
      PIPELINE_ROOT = 'gs://sibr-market'
      CRON_EXPRESSION = '0 2 */3 * *'
      TIME_ZONE = 'Europe/Oslo'

      aiplatform.init(project=PROJECT_ID, location=LOCATION)

      print(f"Looking for existing schedule with display name: {SCHEDULE_NAME}")
      schedules = aiplatform.PipelineJobSchedule.list(
          filter=f'display_name="{SCHEDULE_NAME}"'
      )

      if schedules:
          print("Found existing schedule. Pausing, updating, and resuming.")
          schedule = schedules[0]
          
          print(f"Pausing schedule: {schedule.resource_name}")
          schedule.pause()

          # Oppdater kun pipeline-spesifikasjonen (malen)
          schedule.update(
              pipeline_spec_uri=PIPELINE_SPEC_URI,
          )
          print(f"Schedule updated to use new pipeline spec: {PIPELINE_SPEC_URI}")

          print(f"Resuming schedule: {schedule.resource_name}")
          schedule.resume()
          print("Schedule successfully updated and resumed.")

      else:
          print("No existing schedule found. Creating a new one.")
          aiplatform.PipelineJobSchedule.create(
              display_name=SCHEDULE_NAME,
              cron=CRON_EXPRESSION,
              pipeline_spec_uri=PIPELINE_SPEC_URI,
              pipeline_root=PIPELINE_ROOT,
              time_zone=TIME_ZONE,
              enable_caching=False # Anbefales for å sikre at nye data brukes
          )
          print("Successfully created a new schedule.")

      EOF

      # Kjør skriptet
      python submit_or_update_schedule.py

# ---- Images (kommentert ut for nå) ----
#images:
#- 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/scraping:${COMMIT_SHA}'
#- 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/geocoding:${COMMIT_SHA}'
#- 'europe-west1-docker.pkg.dev/sibr-market/sibr-market-repo/modeling:${COMMIT_SHA}'